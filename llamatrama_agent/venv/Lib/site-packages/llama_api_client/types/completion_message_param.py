# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from __future__ import annotations

from typing import Union, Iterable
from typing_extensions import Literal, Required, TypeAlias, TypedDict

from .message_text_content_item_param import MessageTextContentItemParam

__all__ = ["CompletionMessageParam", "Content", "ToolCall", "ToolCallFunction"]

Content: TypeAlias = Union[str, MessageTextContentItemParam]


class ToolCallFunction(TypedDict, total=False):
    arguments: Required[str]
    """
    The arguments to call the function with, as generated by the model in JSON
    format. Note that the model does not always generate valid JSON, and may
    hallucinate parameters not defined by your function schema. Validate the
    arguments in your code before calling your function.
    """

    name: Required[str]
    """The name of the function to call."""


class ToolCall(TypedDict, total=False):
    id: Required[str]
    """The ID of the tool call."""

    function: Required[ToolCallFunction]
    """The function that the model called."""


class CompletionMessageParam(TypedDict, total=False):
    role: Required[Literal["assistant"]]
    """Must be "assistant" to identify this as the model's response"""

    content: Content
    """The content of the model's response."""

    stop_reason: Literal["stop", "tool_calls", "length"]
    """The reason why we stopped.

    Options are: - "stop": The model reached a natural stopping point. -
    "tool_calls": The model finished generating and invoked a tool call. - "length":
    The model reached the maxinum number of tokens specified in the request.
    """

    tool_calls: Iterable[ToolCall]
    """The tool calls generated by the model, such as function calls."""
